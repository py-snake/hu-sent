{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hungarian Sentiment Analysis with HuBERT\n",
    "\n",
    "This notebook demonstrates sentiment analysis using a fine-tuned Hungarian BERT model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T13:36:55.922750200Z",
     "start_time": "2025-05-03T13:36:46.255257200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\temp\\py\\hu-sent\\venv\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T13:37:10.600055900Z",
     "start_time": "2025-05-03T13:36:55.931132100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"SZTAKI-HLT/hubert-base-cc\"  # Same as training\n",
    "MAX_LENGTH = 128  # Same as training\n",
    "LABEL_MAP = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}  # Reverse mapping\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T13:37:10.605706300Z",
     "start_time": "2025-05-03T13:37:10.595888800Z"
    }
   },
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Use [CLS] token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        return self.fc(pooled_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T13:37:10.668013Z",
     "start_time": "2025-05-03T13:37:10.610740800Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    # Initialize model with same architecture as training\n",
    "    model = SentimentClassifier(MODEL_NAME, num_classes=3).to(DEVICE)\n",
    "\n",
    "    # Load trained weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T13:37:10.698558800Z",
     "start_time": "2025-05-03T13:37:10.631253800Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(DEVICE)\n",
    "    attention_mask = encoding['attention_mask'].to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "    return LABEL_MAP[preds.cpu().item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T13:37:20.190495700Z",
     "start_time": "2025-05-03T13:37:10.651880400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Ez a film fantasztikus volt!\n",
      "Sentiment: positive\n",
      "--------------------------------------------------\n",
      "Text: Nem tetszett a könyv.\n",
      "Sentiment: negative\n",
      "--------------------------------------------------\n",
      "Text: Átlagos élmény volt, semmi különös.\n",
      "Sentiment: negative\n",
      "--------------------------------------------------\n",
      "Text: Süt a nap.\n",
      "Sentiment: neutral\n",
      "--------------------------------------------------\n",
      "Text: Esik az eső.\n",
      "Sentiment: neutral\n",
      "--------------------------------------------------\n",
      "Text: Szép időnk van ma.\n",
      "Sentiment: positive\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model (make sure 'best_model.pt' is in your directory)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = load_model(\"best_model.pt\")  # Replace with your actual model path\n",
    "\n",
    "# Example predictions\n",
    "texts = [\n",
    "    \"Ez a film fantasztikus volt!\",\n",
    "    \"Nem tetszett a könyv.\",\n",
    "    \"Átlagos élmény volt, semmi különös.\",\n",
    "    \"Süt a nap.\",\n",
    "    \"Esik az eső.\",\n",
    "    \"Szép időnk van ma.\",\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    sentiment = predict_sentiment(text, model, tokenizer)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentiment: {sentiment}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T13:37:20.549102Z",
     "start_time": "2025-05-03T13:37:20.196126900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Ez a modell nagyon jól működik!\n",
      "Predicted sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "#@title Enter your own Hungarian text\n",
    "user_text = \"Ez a modell nagyon jól működik!\" #@param {type:\"string\"}\n",
    "\n",
    "if user_text.strip():\n",
    "    sentiment = predict_sentiment(user_text, model, tokenizer)\n",
    "    print(f\"Text: {user_text}\")\n",
    "    print(f\"Predicted sentiment: {sentiment}\")\n",
    "else:\n",
    "    print(\"Please enter some text for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
